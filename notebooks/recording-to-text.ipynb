{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "aai_api_file = Path('../.assemblyai')\n",
    "transcript = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai.settings.api_key = aai_api_file.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_URL = str(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = aai.TranscriptionConfig(speaker_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = aai.Transcriber()\n",
    "if not transcript:\n",
    "  transcript = transcriber.transcribe(\n",
    "    FILE_URL,\n",
    "    config=config\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if you already have a transcript...\n",
    "then you can use the following code to fetch it from the assembly AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_transcript_id = 'f136391e-caad-415a-abe3-75b652e2e848'\n",
    "client = aai.Client()\n",
    "ts = aai.Transcript.get_by_id(existing_transcript_id)\n",
    "ts.utterances[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the speaker-specific lines out to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = Path(audio_file.name + '.assemblyai.out')\n",
    "\n",
    "with output_file.open('a') as f:\n",
    "  for utterance in ts.utterances:\n",
    "    f.write(f\"{utterance.speaker}::{utterance.text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the above transcript through openai's GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = Path('../.openai')\n",
    "os.environ['OPENAI_API_KEY'] = openai_key.read_text()\n",
    "openai_client = openai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"You are a knowledgable software architect. You're reviewing a transcript of two other knowledgable software architects that are having a discussion. Your job is to copy-edit this transcript. Get rid of the filler words (um, like), get rid of repeated words and fix the punctuation. After you're done copy-editing, please provide your summary at the end. Also list out what you believe the next steps to be. Thanks!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.read_text().split('\\n')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for post-processing\n",
    "model = 'gpt-3.5-turbo'\n",
    "# model = 'gpt-4-turbo'\n",
    "# you'll need to set this parameter based on whatever model you select. the models have different token lengths,\n",
    "# which you can find here: https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4\n",
    "tokens_per_model = {\n",
    "    'gpt-3.5-turbo': 16_385//4,\n",
    "    'gpt-4-turbo': 30_000,\n",
    "}\n",
    "max_tokens = tokens_per_model[model]\n",
    "temperature=0\n",
    "gpt4_postprocessing_file = Path(str(output_file.absolute()) + model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how many tokens are in the proposed input file\n",
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(model)\n",
    "# split up the input based on the maximum token length for the model\n",
    "splits: List[Tuple[int, str]] = []\n",
    "split: List[str] = []\n",
    "total_tokens = 0\n",
    "for line_num, line in enumerate(output_file.read_text().split('\\n')):\n",
    "    ntokens = len(enc.encode(line))\n",
    "    if total_tokens + ntokens > max_tokens:\n",
    "        print(f'making a split at {line_num+1}')\n",
    "        splits.append((total_tokens, split))\n",
    "        total_tokens = ntokens\n",
    "        split = []\n",
    "\n",
    "    split.append(line)\n",
    "    total_tokens += ntokens\n",
    "\n",
    "if split:\n",
    "    splits.append((total_tokens, split))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (ntokens, split) in enumerate(splits):\n",
    "    print(f'split: {idx+1} has {ntokens} tokens and {len(split)} lines of conversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for idx, split in enumerate(splits):\n",
    "    tokens, lines = split\n",
    "    print(f'processing line {idx+1} / {len(splits)}')\n",
    "    if idx == 0:\n",
    "        message_content = \"This is the beginning of the conversation.\"\n",
    "    else:\n",
    "        prev_tokens, prev_lines = splits[idx-1]\n",
    "        message_content = \"Here is the last few minutes of conversation. Please use this as context for the next set of transcript that you're going to receive. Do not provide edits on the content of this message. Thanks!\\n\" + '\\n'.join(prev_lines)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message_content\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"This is the part of the transcript that I want you to edit. Please only edit this part and return it as your response. Thanks!:\" + '\\n'.join(lines)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=messages\n",
    "    )\n",
    "    responses.append(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('try9', 'w') as f:\n",
    "    f.write(f'Prompt: {prompt}\\n')\n",
    "    f.write(f'Model: {model}\\n')\n",
    "    for idx, response in enumerate(responses):\n",
    "        f.write('-----------------------------------------------\\n')\n",
    "        f.write(f'RESPONSE: {idx+1}/{len(splits)}\\n')\n",
    "        f.write('\\n\\n'.join(response.choices[0].message.content.split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recording-to-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
